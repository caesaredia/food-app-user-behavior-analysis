{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing User Experience: Behavioral Insights and A/A/B Testing in a Food Delivery App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "# Table of Contents <a id='back'></a>\n",
    "\n",
    "[Introduction](#mulai)\n",
    "1. [Understanding the Sales Funnel](#persiapan)\n",
    "    * [Data Preparation](#persiapandata)\n",
    "    * [Data Learning](#pelajaridata)\n",
    "    * [Funnel Exploration](#pelajarifunnel)\n",
    "2. [A/A/B Testing Experiment](#eksperimen)\n",
    "3. [Conclusion & Recommendation](#kesimpulan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Introduction\n",
    "<a id=\"mulai\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ever-evolving digital era, understanding user behavior has become crucial for every company, especially for technology-based startups such as the food company featured in this case study. By gaining insight into how users interact with their application, the company can make better decisions in product design, improve user experience, and ultimately increase their business success rate.\r\n",
    "\r\n",
    "In this project, we will discuss user behavior analysis for a startup that sells food products. Our approach consists of several stages:\r\n",
    "\r\n",
    "1. **Understanding the Sales Funnel**: We will examine the sales funnel of this companyâ€™s application. The sales funnel will help us understand the user journey from the initial stage to the point of purchase, as well as identify potential drop-off points where users are lost.\r\n",
    "\r\n",
    "2. **A/A/B Testing Experiment**: We will introduce the A/A/B testing experiment conducted by the company to evaluate changes in their app, particularly regarding font design. We will analyze the results of this experiment to determine whether the change had a positive or negative impact on user experience.\r\n",
    "\r\n",
    "3. **Conclusion and Recommendations**: We will summarize our findings from the user behavior analysis and the A/A/B testing results, and provide recommendations for the company on how to optimize their product.\r\n",
    "\r\n",
    "Thus, this project will not only offer deep insights into user behavior and experimental outcomes but also assist the company in making smarter decisions for developing and enhancing their product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='persiapan'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Understanding the Sales Funnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persiapan Data\n",
    "<a id=\"persiapandata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/food_app_user_behavior_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventName\\tDeviceIDHash\\tEventTimestamp\\tExpId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MainScreenAppear\\t4575588528974610257\\t1564029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MainScreenAppear\\t7416695313311560658\\t1564053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PaymentScreenSuccessful\\t3518123091307005509\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CartScreenAppear\\t3518123091307005509\\t1564054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaymentScreenSuccessful\\t6217807653094995999\\t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EventName\\tDeviceIDHash\\tEventTimestamp\\tExpId\n",
       "0  MainScreenAppear\\t4575588528974610257\\t1564029...\n",
       "1  MainScreenAppear\\t7416695313311560658\\t1564053...\n",
       "2  PaymentScreenSuccessful\\t3518123091307005509\\t...\n",
       "3  CartScreenAppear\\t3518123091307005509\\t1564054...\n",
       "4  PaymentScreenSuccessful\\t6217807653094995999\\t..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first 5 rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/food_app_user_behavior_data.csv')\n",
    "\n",
    "# change column name\n",
    "data.columns = ['event_name', 'device_id_hash', 'event_timestamp', 'exp_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244126 entries, 0 to 244125\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   event_name       244126 non-null  object\n",
      " 1   device_id_hash   244126 non-null  int64 \n",
      " 2   event_timestamp  244126 non-null  int64 \n",
      " 3   exp_id           244126 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# general information about data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_name         0\n",
       "device_id_hash     0\n",
       "event_timestamp    0\n",
       "exp_id             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert `event_timestamp` into datetime data type\n",
    "data['event_date_time'] = pd.to_datetime(data['event_timestamp'], unit='s')\n",
    "\n",
    "# add date and time columns and a separate column for date\n",
    "data['date'] = data['event_date_time'].dt.date\n",
    "\n",
    "# convert `device_id_hash` into string data type\n",
    "data['device_id_hash'] = data['device_id_hash'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>device_id_hash</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>exp_id</th>\n",
       "      <th>event_date_time</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MainScreenAppear</td>\n",
       "      <td>4575588528974610257</td>\n",
       "      <td>1564029816</td>\n",
       "      <td>246</td>\n",
       "      <td>2019-07-25 04:43:36</td>\n",
       "      <td>2019-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MainScreenAppear</td>\n",
       "      <td>7416695313311560658</td>\n",
       "      <td>1564053102</td>\n",
       "      <td>246</td>\n",
       "      <td>2019-07-25 11:11:42</td>\n",
       "      <td>2019-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PaymentScreenSuccessful</td>\n",
       "      <td>3518123091307005509</td>\n",
       "      <td>1564054127</td>\n",
       "      <td>248</td>\n",
       "      <td>2019-07-25 11:28:47</td>\n",
       "      <td>2019-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CartScreenAppear</td>\n",
       "      <td>3518123091307005509</td>\n",
       "      <td>1564054127</td>\n",
       "      <td>248</td>\n",
       "      <td>2019-07-25 11:28:47</td>\n",
       "      <td>2019-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaymentScreenSuccessful</td>\n",
       "      <td>6217807653094995999</td>\n",
       "      <td>1564055322</td>\n",
       "      <td>248</td>\n",
       "      <td>2019-07-25 11:48:42</td>\n",
       "      <td>2019-07-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_name       device_id_hash  event_timestamp  exp_id  \\\n",
       "0         MainScreenAppear  4575588528974610257       1564029816     246   \n",
       "1         MainScreenAppear  7416695313311560658       1564053102     246   \n",
       "2  PaymentScreenSuccessful  3518123091307005509       1564054127     248   \n",
       "3         CartScreenAppear  3518123091307005509       1564054127     248   \n",
       "4  PaymentScreenSuccessful  6217807653094995999       1564055322     248   \n",
       "\n",
       "      event_date_time        date  \n",
       "0 2019-07-25 04:43:36  2019-07-25  \n",
       "1 2019-07-25 11:11:42  2019-07-25  \n",
       "2 2019-07-25 11:28:47  2019-07-25  \n",
       "3 2019-07-25 11:28:47  2019-07-25  \n",
       "4 2019-07-25 11:48:42  2019-07-25  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate values in `exp_id` column\n",
    "valid_exp_ids = [246, 247, 248]\n",
    "invalid_exp_ids = data[~data['exp_id'].isin(valid_exp_ids)]\n",
    "if not invalid_exp_ids.empty:\n",
    "    print(\"Nilai-nilai tidak valid dalam kolom exp_id:\", invalid_exp_ids['exp_id'].unique())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation Steps:\n",
    "\n",
    "1. The dataset was confirmed to contain no missing values, ensuring data completeness for subsequent analysis.\n",
    "2. The `event_timestamp` field was converted to a datetime format to enable accurate and efficient time-based analyses.\n",
    "3. Additional columns were derived to separately capture the full timestamp, the date, and the time components, facilitating granular temporal analysis.\n",
    "4. The `device_id_hash` field was cast to a string type. As this identifier is not intended for numerical computation, treating it as a string minimizes the risk of errors during data manipulation and ensures semantic clarity.\n",
    "5. The values within the `exp_id` column were examined to confirm their validity. Specifically, we verified that only the expected identifiers (246, 247, and 248) were present, and that no extraneous or anomalous values existed in the dataset.alues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Learning\n",
    "<a id=\"pelajaridata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events in log: 244126\n"
     ]
    }
   ],
   "source": [
    "# how many events recorded in log?\n",
    "total_events = data.shape[0]\n",
    "print(\"Total events in log:\", total_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users in log: 7551\n"
     ]
    }
   ],
   "source": [
    "# how many users recorded in log?\n",
    "total_users = data['device_id_hash'].nunique()\n",
    "print(\"Total users in log:\", total_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average events per users: 32.33028737915508\n"
     ]
    }
   ],
   "source": [
    "# what is the average number of events per user?\n",
    "avg_events_per_user = total_events / total_users\n",
    "print(\"Average events per users:\", avg_events_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum date: 2019-07-25 04:43:36\n",
      "Maximum date: 2019-08-07 21:15:17\n"
     ]
    }
   ],
   "source": [
    "# what time period is covered by the data?\n",
    "min_date = data['event_date_time'].min()\n",
    "max_date = data['event_date_time'].max()\n",
    "print(\"Minimum date:\", min_date)\n",
    "print(\"Maximum date:\", max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1937635139.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    mport matplotlib.pyplot as plt\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# histogram based on date and time\n",
    "mport matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(data['event_date_time'], bins=30, color='orange', edgecolor='black')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram Date and Time Event')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting total events per date\n",
    "events_per_date = data.groupby('date').size()\n",
    "\n",
    "# visualize event distribution per date\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(events_per_date.index, events_per_date.values, marker='o', linestyle='-')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Events')\n",
    "plt.title('Event Distribution per Date')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that we have users from three experiment group\n",
    "exp_group = data['exp_id'].unique()\n",
    "print(\"Experiment group recorded in data:\", exp_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Total number of events in the log: 244,126\n",
    "2. Total number of users recorded: 7,551\n",
    "3. Average number of events per user: 32.33\n",
    "4. Earliest timestamp in the dataset: July 25, 2019, 04:43:36\n",
    "5. Latest timestamp in the dataset: August 7, 2019, 21:15:17\n",
    "6. Experimental groups represented in the data: [246, 248, 247]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Funnel Exploration\n",
    "<a id=\"pelajarifunnel\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the events present in the log and their frequencies of occurrence.\n",
    "event_counts = data['event_name'].value_counts()\n",
    "print(\"Event frequencies of occurrence:\")\n",
    "\n",
    "event_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of users who performed each action\n",
    "user_counts = data.groupby('event_name')['device_id_hash'].nunique().sort_values(ascending=False)\n",
    "print(\"The number of users who performed each action:\")\n",
    "\n",
    "user_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of users who performed each action\n",
    "user_per_event = data.groupby('event_name')['device_id_hash'].nunique().reset_index()\n",
    "user_per_event.columns = ['event_name', 'unique_users']\n",
    "user_per_event = user_per_event.sort_values(by='unique_users', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user proportion who perform one time\n",
    "user_total = data['device_id_hash'].nunique()\n",
    "one_time_user = user_per_event['unique_users'].sum()\n",
    "prop_one_time_user = one_time_user / user_total * 100\n",
    "print(\"User proportion who perform at least one time:\", prop_one_time_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event funnel: the percentage of users who progressed from one stage to the next.\n",
    "funnel = user_per_event.copy()\n",
    "funnel['retention_rate'] = funnel['unique_users'].pct_change() * 100\n",
    "funnel = funnel.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the stage at which user drop-off occurs\n",
    "loss = funnel[funnel['retention_rate'] < 0]['event_name'].iloc[0]\n",
    "print(\"Tahap di mana kehilangan pengguna terjadi:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the percentage of users who successfully completed all stages\n",
    "first_user = funnel.iloc[0]['unique_users']\n",
    "last_user = funnel.iloc[-1]['unique_users']\n",
    "persentase_penyelesaian = (last_user / first_user) * 100\n",
    "print(\"The percentage of users who successfully completed all stages:\", persentase_penyelesaian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Event Frequency:\n",
    "- MainScreenAppear: 119,205 occurrences\n",
    "- OffersScreenAppear: 46,825 occurrences\n",
    "- CartScreenAppear: 42,731 occurrences\n",
    "- PaymentScreenSuccessful: 34,313 occurrences\n",
    "- Tutorial: 1,052 occurrences\n",
    "\n",
    "2. Number of Users who performed each action:\n",
    "- MainScreenAppear: 7,439 users\n",
    "- OffersScreenAppear: 4,613 users\n",
    "- CartScreenAppear: 3,749 users\n",
    "- PaymentScreenSuccessful: 3,547 users\n",
    "- Tutorial: 847 users\n",
    "\n",
    "3. Proportion of users who performed at least one action: 267.45%\n",
    "4. Stage where the highest user drop-off occurs: OffersScreenAppear\n",
    "5. Percentage of users who successfully completed all stages: 18.36%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A/A/B Testing Experiment\n",
    "<a id=\"eksperimen\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many users in each group?\n",
    "group_counts = data.groupby('exp_id')['device_id_hash'].nunique().reset_index()\n",
    "group_counts.columns = ['exp_id', 'user_counts']\n",
    "print(\"Total users in every experiment group:\")\n",
    "print(group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find significant difference between control group\n",
    "control_group_A = data[(data['exp_id'] == 246) | (data['exp_id'] == 247)]\n",
    "control_group_B = data[data['exp_id'] == 248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most popular event\n",
    "most_popular_event = data['event_name'].value_counts().idxmax()\n",
    "\n",
    "print(\"Most popular event:\", most_popular_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def analyze_event(df, event_name):\n",
    "    # Find the number of users who performed each event within each control group.\n",
    "    control_group_A = data[(data['exp_id'] == 246) | (data['exp_id'] == 247)]\n",
    "    control_group_B = data[data['exp_id'] == 248]\n",
    "\n",
    "    users_control_A = control_group_A[control_group_A['event_name'] == event_name]['device_id_hash'].nunique()\n",
    "    users_control_B = control_group_B[control_group_B['event_name'] == event_name]['device_id_hash'].nunique()\n",
    "\n",
    "    # Count the percentage\n",
    "    group_counts = data.groupby('exp_id')['device_id_hash'].nunique().reset_index()\n",
    "    group_counts.columns = ['exp_id', 'user_counts']\n",
    "    percent_control_A = (users_control_A / group_counts.loc[group_counts['exp_id'] == 246, 'user_counts'].values[0]) * 100\n",
    "    percent_control_B = (users_control_B / group_counts.loc[group_counts['exp_id'] == 248, 'user_counts'].values[0]) * 100\n",
    "\n",
    "    # Statistic test\n",
    "    contingency_table = pd.crosstab(df['exp_id'], df['event_name'])\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "    # Show the outcome\n",
    "    print(f\"Peristiwa: {event_name}\")\n",
    "    print(f\"Total users in control group A who performed the event: {users_control_A}\")\n",
    "    print(f\"Total users in control group B who performed the event: {users_control_B}\")\n",
    "    print(f\"Percentage of users in control group A: {percent_control_A:.2f}%\")\n",
    "    print(f\"Percentage of users in control group B: {percent_control_B:.2f}%\")\n",
    "    print(f\"Statistic test chi-squared: chi2 = {chi2}, p-value = {p}\")\n",
    "    if p < 0.05:\n",
    "        print(\"The difference between the groups is statistically significant.\")\n",
    "    else:\n",
    "        print(\"The difference between the groups is not statistically significant.\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# find the most popular event\n",
    "most_popular_event_control = control_group_A['event_name'].value_counts().idxmax()\n",
    "most_popular_event_experimental = control_group_B['event_name'].value_counts().idxmax()\n",
    "\n",
    "# analyze and test the statistic for each event\n",
    "for event in data['event_name'].unique():\n",
    "    analyze_event(data, event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of statistic hypotheses test\n",
    "total_tests = 2 * len(data['event_name'].unique())\n",
    "print(\"Total statistic hypotheses test performed:\", total_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Conclusion & Recommendation\n",
    "<a id=\"kesimpulan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Data Preparation Steps\n",
    "1. **Reading the Data File**: The CSV data file was read using `pd.read_csv()`.\n",
    "2. **Column Name Adjustment**: Column names were modified as needed using the `.columns` attribute.\n",
    "3. **General Data Overview**: A general overview of the dataset was examined using `.info()` to ensure no missing values and to review column data types.\n",
    "4. **Missing Value Check**: Missing values were checked using `.isnull().sum()` to confirm data completeness.\n",
    "5. **Data Type Conversion**: The `event_timestamp` column was converted to datetime format using `pd.to_datetime()`. Additionally, the `device_id_hash` column was converted to a string, as device IDs do not require mathematical operations.\n",
    "6. **Date Column Addition**: A new column `event_date_time` was added to store timestamps in datetime format. Another column, date, was created to extract and store only the date component.\n",
    "7. **Validation of exp_id Values**: A check was conducted to ensure that the `exp_id` column contained only valid values consistent with the expected experimental groups.\n",
    "8. **Displaying the Data**: The first five rows of the prepared dataset were displayed using `.head()` to verify that all changes had been applied correctly.\n",
    "\n",
    "Following these data preparation steps, the dataset was ready for further analysis. No missing values were found, all columns were properly typed, and the inclusion of date fields and validation of experimental groups ensured high data quality. The dataset was thus well-suited for subsequent analysis and modeling.\n",
    "\n",
    "### Data Analysis\n",
    "1. **Total Events in the Log**: The log contains a total of 244,126 events.\n",
    "2. **Total Users in the Log**: There are 7,551 distinct users recorded in the log.\n",
    "3. **Average Events per User**: On average, each user generated approximately 32.33 events.\n",
    "4. **Data Time Range**: The dataset covers the period from July 25, 2019, to August 7, 2019.\n",
    "5. **Histogram of Event Timestamps**: A histogram visualizes the temporal distribution of events, revealing fluctuations in event frequency over time.\n",
    "6. **Event Distribution by Date**: A separate plot illustrates the daily distribution of events, highlighting spikes in activity that may correspond to specific events or changes in the app.\n",
    "7. **Experiment Groups**: Users are represented across all three experimental groupsâ€”246, 247, and 248â€”ensuring balanced representation for analysis.\n",
    "\n",
    "**Conclusion:**\n",
    "- The dataset contains a substantial volume of events over approximately two weeks.\n",
    "- The average number of events per user is around 32.\n",
    "- Daily variations in activity suggest user behavior may be influenced by external or app-related factors.\n",
    "- All experimental groups are present in the data, allowing for valid comparative analysis.\n",
    "\n",
    "### Funnel Analysis\n",
    "From the funnel analysis, the following conclusions can be drawn:\n",
    "\n",
    "1. **Event Frequency**: MainScreenAppear is the most frequently occurring event, followed by OffersScreenAppear, CartScreenAppear, PaymentScreenSuccessful, and finally Tutorial.\n",
    "2. **Number of Users per Event**: The number of users performing each event decreases through the funnel, with the highest count at MainScreenAppear and the lowest at Tutorial.\n",
    "3. **Proportion of Users Performing at Least One Action**: Approximately 267.45%, which suggests that many users performed multiple actions.\n",
    "4. **Event Funnel**: The percentage of users progressing from one stage to the next drops notably at the OffersScreenAppear stage, indicating significant user attrition.\n",
    "5. **User Drop-off**: The most substantial drop-off occurs at the OffersScreenAppear stage. This may point to a usability or engagement issue at this point in the app.\n",
    "6. **Users Completing the Entire Funnel**: Around 18.36% of users successfully completed all funnel stages, indicating a challenge in retaining users through to conversion.\n",
    "\n",
    "### A/A/B Testing\n",
    "Based on the A/A/B testing analysis, the following insights and recommendations emerge:\n",
    "\n",
    "1. User Distribution Across Groups: The three experimental groups are relatively balanced, each with approximately 2,500 users.\n",
    "2. Most Popular Event: The MainScreenAppear event is the most frequently recorded across all groups.\n",
    "3. Event Analysis: All key events showed statistically significant differences between the control and experimental groups. This is supported by very low p-values (< 0.05) from chi-squared tests, indicating that group differences are unlikely due to chance.\n",
    "4. Total Hypothesis Tests Conducted: Ten hypothesis tests were performedâ€”covering each event across the control (A), second control (A), and experimental (B) groups, as per standard A/A/B testing protocols.\n",
    "\n",
    "## Recommendations\n",
    "1. **Validate Findings**: Despite statistically significant results, it's important to validate these findings by considering other variables that may influence user behavior, such as demographics or historical activity.\n",
    "2. **Deeper Analysis**: Conduct further analysis to explore factors behind the observed group differences. This may include segmenting users by prior behavior or external conditions.\n",
    "3. **Experiment Optimization**: If the tested changes led to positive outcomes (e.g., higher conversion or retention rates), consider rolling out those changes more broadly.\n",
    "4. **Iterate and Monitor**: A/A/B testing is inherently iterative. After implementing changes, continue monitoring user behavior and perform follow-up tests to refine the product further.\n",
    "5. **Control for Multiple Testing**: Given the number of hypothesis tests, be cautious of Type I errors. Employing a conservative significance threshold (e.g., 0.05 or lower) helps mitigate the risk of false positives due to multiple comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
